{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Classifier Class\n",
    "Contains function for top k accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CnnClassifier(nn.Module):\n",
    "    # n_hidden: number of units at the last fc layer\n",
    "    def __init__(self, n_hidden, pt_layers=None):\n",
    "        super(CnnClassifier, self).__init__()\n",
    "\n",
    "        # in_data size: (batch_size, 1, 28, 28)\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            # conv1_out size: (batch_size, 4, 26, 26)\n",
    "            nn.Conv2d(in_channels=1, out_channels=4, kernel_size=(3, 3), stride=(1, 1), padding=0),\n",
    "            nn.ReLU(),\n",
    "            # conv2_out size: (batch_size, 8, 12, 12)\n",
    "            nn.Conv2d(in_channels=4, out_channels=8, kernel_size=(3, 3), stride=(2, 2), padding=0),\n",
    "            nn.ReLU(),\n",
    "            # conv3_out size: (batch_size, 16, 5, 5)\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), stride=(2, 2), padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, return_indices=False, ceil_mode=False),\n",
    "            # conv4_out size: (batch_size, 32, 1, 1)\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), stride=(1, 1), padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        if pt_layers is not None:\n",
    "            self.cnn_layers.load_state_dict(pt_layers)\n",
    "        # linear layers transforms flattened image features into logits before the softmax layer\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(32, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, 47)  # there are 10 classes\n",
    "        )\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.loss_fn = nn.CrossEntropyLoss(reduction='sum')  # will be divided by batch size\n",
    "\n",
    "    def forward(self, in_data):\n",
    "        img_features = self.cnn_layers(in_data).view(in_data.size(0), 32)\n",
    "        logits = self.linear(img_features)\n",
    "        return logits\n",
    "\n",
    "    def loss(self, logits, labels):\n",
    "        return self.loss_fn(logits, labels) / logits.size(0)\n",
    "\n",
    "    def top1_accuracy(self, logits, labels):\n",
    "        # get argmax of logits along dim=1 (this is equivalent to argmax of predicted probabilites)\n",
    "        predicted_labels = torch.argmax(logits, dim=1, keepdim=False)  # size (batch_size,)\n",
    "        n_corrects = predicted_labels.eq(labels).sum(0)  # sum up all the correct predictions\n",
    "        return n_corrects / logits.size(0) * 100  # in percentage\n",
    "\n",
    "    def topk_accuracy(self, k, logits, labels):\n",
    "        predicted_labels = torch.topk(logits, k, dim=1)[1]\n",
    "        n_corrects = torch.tensor([0])\n",
    "        for i in range(k):\n",
    "            n_corrects += predicted_labels[:, i].eq(labels).sum(0)\n",
    "        return n_corrects.double() / logits.size(0) * 100  # in percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class LocalEMNIST(Dataset):\n",
    "    '''\n",
    "    ds: emnist dataset provided in project files\n",
    "    flatten: bool, flatten it or not\n",
    "    '''\n",
    "\n",
    "    def __init__(self, ds, flatten):\n",
    "        self.flatten = flatten\n",
    "        self.ds = ds\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.ds[index]\n",
    "        image = image.view(-1) if self.flatten else image\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to download EMNIST dataset and to show images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import EMNIST\n",
    "from torch.utils.data import ConcatDataset, Subset\n",
    "from torchvision.transforms import ToTensor, Compose\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def show_image(dataset, index):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.imshow(dataset[index][0][0], cmap=plt.get_cmap('gray'))\n",
    "\n",
    "\n",
    "def get_datasets(split='balanced', save=False):\n",
    "    download_folder = './data'\n",
    "\n",
    "    transform = Compose([ToTensor()])\n",
    "\n",
    "    dataset = ConcatDataset([EMNIST(root=download_folder, split=split, download=True, train=False, transform=transform),\n",
    "                             EMNIST(root=download_folder, split=split, download=True, train=True, transform=transform)])\n",
    "\n",
    "    # Ignore the code below with argument 'save'\n",
    "    if save:\n",
    "        random_seed = 4211  # do not change\n",
    "        n_samples = len(dataset)\n",
    "        eval_size = 0.2\n",
    "        indices = list(range(n_samples))\n",
    "        split = int(np.floor(eval_size * n_samples))\n",
    "\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        train_indices, eval_indices = indices[split:], indices[:split]\n",
    "\n",
    "        # cut to half\n",
    "        train_indices = train_indices[:len(train_indices) // 2]\n",
    "        eval_indices = eval_indices[:len(eval_indices) // 2]\n",
    "\n",
    "        np.savez('train_test_split.npz', train=train_indices, test=eval_indices)\n",
    "\n",
    "    # just use save=False for students\n",
    "    # load train test split indices\n",
    "    else:\n",
    "        with np.load('./train_test_split.npz') as f:\n",
    "            train_indices = f['train']\n",
    "            eval_indices = f['test']\n",
    "\n",
    "    train_dataset = Subset(dataset, indices=train_indices)\n",
    "    eval_dataset = Subset(dataset, indices=eval_indices)\n",
    "\n",
    "    return train_dataset, eval_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loaders, optimizer, writer, n_epochs, ckpt_path, device='cpu', train_type=''):\n",
    "    def run_epoch(train_or_eval, num_epoch):\n",
    "        \n",
    "        epoch_loss = 0.\n",
    "        epoch_acc = 0.\n",
    "        epoch_acc_top3 = 0.\n",
    "        \n",
    "        for i, batch in enumerate(loaders[train_or_eval], 1):\n",
    "            in_data, labels = batch\n",
    "            in_data, labels = in_data.to(device), labels.to(device)\n",
    "            \n",
    "            if train_or_eval == 'train':\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            logits = model(in_data)\n",
    "            batch_loss = model.loss(logits, labels)\n",
    "            batch_acc = model.topk_accuracy(1, logits, labels)\n",
    "            batch_acc_top3 = model.topk_accuracy(3, logits, labels)\n",
    "\n",
    "            epoch_loss += batch_loss.item()\n",
    "            epoch_acc += batch_acc.item()\n",
    "            epoch_acc_top3 += batch_acc_top3.item()\n",
    "\n",
    "            if train_or_eval == 'train':\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        epoch_loss /= i\n",
    "        epoch_acc /= i\n",
    "        epoch_acc_top3 /= i\n",
    "\n",
    "        losses[num_epoch][train_or_eval] = epoch_loss\n",
    "        accs_top1[num_epoch][train_or_eval] = epoch_acc\n",
    "        accs_top3[num_epoch][train_or_eval] = epoch_acc_top3\n",
    "\n",
    "        if writer is None:\n",
    "            print('epoch %d %s loss %.4f acc %.4f acc_top3 %.4f' % (epoch, train_or_eval, epoch_loss, epoch_acc, epoch_acc_top3))\n",
    "        elif train_or_eval == 'eval':\n",
    "            name = \"%s-n_hid-%d-lr-%.3f\" % (train_type, model.linear[0].out_features, optimizer.param_groups[0][\"lr\"])\n",
    "            writer.add_scalars('%s_loss' % name,\n",
    "                               tag_scalar_dict={'train': losses[num_epoch]['train'],\n",
    "                                                'eval': losses[num_epoch]['eval']},\n",
    "                               global_step=epoch)\n",
    "\n",
    "            writer.add_scalars('%s_top1_accuracy' % name,\n",
    "                               tag_scalar_dict={'train': accs_top1[num_epoch]['train'],\n",
    "                                                'eval': accs_top1[num_epoch]['eval']},\n",
    "                               global_step=epoch)\n",
    "\n",
    "            writer.add_scalars('%s_top3_accuracy' % name,\n",
    "                               tag_scalar_dict={'train': accs_top3[num_epoch]['train'],\n",
    "                                                'eval': accs_top3[num_epoch]['eval']},\n",
    "                               global_step=epoch)\n",
    "\n",
    "    # main statements\n",
    "    losses = []\n",
    "    accs_top1 = []\n",
    "    accs_top3 = []\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        \n",
    "        losses.append({\"train\": None, \"eval\": None})\n",
    "        accs_top1.append({\"train\": None, \"eval\": None})\n",
    "        accs_top3.append({\"train\": None, \"eval\": None})\n",
    "        \n",
    "        run_epoch('train', epoch - 1)\n",
    "        run_epoch('eval', epoch - 1)\n",
    "\n",
    "        # For instructional purpose, show how to save checkpoints\n",
    "        if ckpt_path is not None:\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'losses': losses,\n",
    "                'accs': accs_top1\n",
    "            }, '%s/%d.pt' % (ckpt_path, epoch))\n",
    "    \n",
    "    return losses, accs_top1, accs_top3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize params and datasets for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torch.optim import Adam, SGD\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "ckpt_path = None\n",
    "n_epochs = 100\n",
    "batch_size = 128\n",
    "gpu = 0\n",
    "\n",
    "params = [{\"n_hidden\": 32, \"opt_class\": Adam, \"lr\": 0.001},\n",
    "          {\"n_hidden\": 32, \"opt_class\": SGD, \"lr\": 0.1},\n",
    "          {\"n_hidden\": 32, \"opt_class\": SGD, \"lr\": 0.01},\n",
    "          {\"n_hidden\": 64, \"opt_class\": Adam, \"lr\": 0.001},\n",
    "          {\"n_hidden\": 64, \"opt_class\": SGD, \"lr\": 0.1},\n",
    "          {\"n_hidden\": 64, \"opt_class\": SGD, \"lr\": 0.01},]\n",
    "\n",
    "if torch.cuda.is_available() and gpu != -1:\n",
    "    DEVICE = gpu\n",
    "else:\n",
    "    DEVICE = 'cpu'\n",
    "    \n",
    "train_ds, eval_ds = get_datasets()\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(LocalEMNIST(train_ds, flatten=False), batch_size=batch_size, drop_last=False, shuffle=True),\n",
    "    'eval': DataLoader(LocalEMNIST(eval_ds, flatten=False), batch_size=batch_size, drop_last=False)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_eval_indices = np.random.choice(train_ds.indices, int(train_ds.indices.size/5), replace=False)\n",
    "validation_train_indices = np.setdiff1d(train_ds.indices, validation_eval_indices)\n",
    "\n",
    "validation_eval = Subset(train_ds.dataset, indices=validation_eval_indices)\n",
    "validation_train = Subset(train_ds.dataset, indices=validation_train_indices)\n",
    "\n",
    "dataloaders_validation = {\n",
    "    'train': DataLoader(LocalEMNIST(validation_train, flatten=False), batch_size=batch_size, drop_last=False, shuffle=True),\n",
    "    'eval': DataLoader(LocalEMNIST(validation_eval, flatten=False), batch_size=batch_size, drop_last=False)\n",
    "}\n",
    "\n",
    "def getPretrainedModel(device):\n",
    "    if device is not 'cpu':\n",
    "        return torch.load(\"pretrained_encoder.pt\", map_location='cuda:0')['model'][0]\n",
    "    else:\n",
    "        return torch.load(\"pretrained_encoder.pt\")['model'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing training for: {'n_hidden': 32, 'opt_class': <class 'torch.optim.adam.Adam'>, 'lr': 0.001}\n",
      "Performing training for: {'n_hidden': 32, 'opt_class': <class 'torch.optim.sgd.SGD'>, 'lr': 0.1}\n",
      "Performing training for: {'n_hidden': 32, 'opt_class': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01}\n",
      "Performing training for: {'n_hidden': 64, 'opt_class': <class 'torch.optim.adam.Adam'>, 'lr': 0.001}\n",
      "Performing training for: {'n_hidden': 64, 'opt_class': <class 'torch.optim.sgd.SGD'>, 'lr': 0.1}\n",
      "Performing training for: {'n_hidden': 64, 'opt_class': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01}\n"
     ]
    }
   ],
   "source": [
    "for param in params:\n",
    "    n_hidden = param[\"n_hidden\"]\n",
    "    opt_class = param[\"opt_class\"]\n",
    "    lr = param[\"lr\"]\n",
    "    \n",
    "    print(\"Performing training for: \" + str(param))\n",
    "    \n",
    "    model = CnnClassifier(n_hidden).to(DEVICE)\n",
    "    optimizer = opt_class(model.parameters(), lr=lr)\n",
    "    writer = SummaryWriter('./logs/cnn/%s' % opt_class.__name__)\n",
    "    \n",
    "    train(model, dataloaders_validation, optimizer, writer, n_epochs, ckpt_path, DEVICE, \"scratch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing training for: {'n_hidden': 32, 'opt_class': <class 'torch.optim.adam.Adam'>, 'lr': 0.001}\n",
      "Performing training for: {'n_hidden': 32, 'opt_class': <class 'torch.optim.sgd.SGD'>, 'lr': 0.1}\n",
      "Performing training for: {'n_hidden': 32, 'opt_class': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01}\n",
      "Performing training for: {'n_hidden': 64, 'opt_class': <class 'torch.optim.adam.Adam'>, 'lr': 0.001}\n",
      "Performing training for: {'n_hidden': 64, 'opt_class': <class 'torch.optim.sgd.SGD'>, 'lr': 0.1}\n",
      "Performing training for: {'n_hidden': 64, 'opt_class': <class 'torch.optim.sgd.SGD'>, 'lr': 0.01}\n"
     ]
    }
   ],
   "source": [
    "for param in params:\n",
    "    n_hidden = param[\"n_hidden\"]\n",
    "    opt_class = param[\"opt_class\"]\n",
    "    lr = param[\"lr\"]\n",
    "    \n",
    "    print(\"Performing training for: \" + str(param))\n",
    "    \n",
    "    pt = getPretrainedModel(DEVICE).state_dict()\n",
    "    pretrained_model = CnnClassifier(n_hidden, pt_layers=pt).to(DEVICE)\n",
    "    optimizer = opt_class(pretrained_model.parameters(), lr=lr)\n",
    "    writer = SummaryWriter('./logs/cnn/%s' % opt_class.__name__)\n",
    "    \n",
    "    train(pretrained_model, dataloaders_validation, optimizer, writer, n_epochs, ckpt_path, DEVICE, \"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaeDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CaeDecoder, self).__init__()\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=32, out_channels=16, kernel_size=(3, 3), stride=(1, 1), padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=16, out_channels=8, kernel_size=(3, 3), stride=(1, 1), padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=8, out_channels=8, kernel_size=(3, 3), stride=(2, 2), padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=8, out_channels=4, kernel_size=(3, 3), stride=(1, 1), padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=4, out_channels=1, kernel_size=(4, 4), stride=(2, 2), padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.loss_fn = nn.MSELoss(reduction='sum')\n",
    "\n",
    "    def forward(self, in_data):\n",
    "        img = self.conv_layers(in_data)\n",
    "        return img\n",
    "\n",
    "    def loss(self, img, img_in):\n",
    "        return self.loss_fn(img, img_in) / img.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "\n",
    "def train_decoder(model, loaders, optimizer, writer, n_epochs, ckpt_path, device):\n",
    "    \n",
    "    pt = getPretrainedModel(device)\n",
    "    \n",
    "    def run_epoch(train_or_eval, num_epoch):\n",
    "        \n",
    "        epoch_loss = 0.\n",
    "        \n",
    "        for i, batch in enumerate(loaders[train_or_eval], 1):\n",
    "            in_data, labels = batch\n",
    "            in_data, labels = in_data.to(device), labels.to(device)\n",
    "            \n",
    "            if train_or_eval == 'train':\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            img_features = pt(in_data)\n",
    "            imgs = model(img_features)\n",
    "            batch_loss = model.loss(imgs, in_data)\n",
    "\n",
    "            epoch_loss += batch_loss.item()\n",
    "\n",
    "            if train_or_eval == 'train':\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        epoch_loss /= i\n",
    "\n",
    "        losses[num_epoch][train_or_eval] = epoch_loss\n",
    "\n",
    "        if writer is None:\n",
    "            print('epoch %d %s loss %.4f ' % (epoch, train_or_eval, epoch_loss))\n",
    "        elif train_or_eval == 'eval':\n",
    "            name = \"cae-lr-%.3f\" % (optimizer.param_groups[0][\"lr\"])\n",
    "            writer.add_scalars('%s_loss' % name,\n",
    "                               tag_scalar_dict={'train': losses[num_epoch]['train'],\n",
    "                                                'eval': losses[num_epoch]['eval']},\n",
    "                               global_step=epoch)\n",
    "\n",
    "            if epoch % 5 == 0:\n",
    "                if len(in_data.size()) == 2:  # when it is flattened, reshape it\n",
    "                    in_data = in_data.view(-1, 1, 28, 28)\n",
    "\n",
    "                img_grid = make_grid(in_data.to('cpu'))\n",
    "                img_out_grid = make_grid(imgs.to('cpu'))\n",
    "                writer.add_image('%s/eval_input' % model.__class__.__name__, img_grid, epoch)\n",
    "                writer.add_image('%s/eval_output' % model.__class__.__name__, img_out_grid, epoch)\n",
    "\n",
    "    # main statements\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        losses.append({\"train\": None, \"eval\": None})\n",
    "        \n",
    "        run_epoch('train', epoch - 1)\n",
    "        run_epoch('eval', epoch - 1)\n",
    "\n",
    "        # For instructional purpose, show how to save checkpoints\n",
    "        if ckpt_path is not None:\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'losses': losses\n",
    "            }, '%s/%d.pt' % (ckpt_path, epoch))\n",
    "            \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_params = [{\"opt_class\": Adam, \"lr\": 0.001},\n",
    "                  {\"opt_class\": SGD, \"lr\": 0.1},\n",
    "                  {\"opt_class\": SGD, \"lr\": 0.01}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in decoder_params:\n",
    "    opt_class = param[\"opt_class\"]\n",
    "    lr = param[\"lr\"]\n",
    "    \n",
    "    print(\"Performing training for: \" + str(param))\n",
    "    \n",
    "    model = CaeDecoder().to(DEVICE)\n",
    "    optimizer = opt_class(model.parameters(), lr=lr)\n",
    "    writer = SummaryWriter('./logs/cae-lr-%s/%s' % (lr, opt_class.__name__))\n",
    "    \n",
    "    train_decoder(model, dataloaders_validation, optimizer, writer, n_epochs, ckpt_path, DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Selected Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainCnnFromScratch():\n",
    "    n_hidden = 64\n",
    "    opt_class = Adam\n",
    "    lr = 0.001\n",
    "    n_epochs = 50\n",
    "    \n",
    "    model = CnnClassifier(n_hidden).to(DEVICE)\n",
    "    optimizer = opt_class(model.parameters(), lr=lr)\n",
    "    writer = SummaryWriter('./logs/cnn/%s' % opt_class.__name__)\n",
    "    \n",
    "    return train(model, dataloaders, optimizer, writer, n_epochs, ckpt_path, DEVICE, \"test-scratch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainCnnFromPT():\n",
    "    n_hidden = 64\n",
    "    opt_class = Adam\n",
    "    lr = 0.001\n",
    "    n_epochs = 50\n",
    "    \n",
    "    pt = getPretrainedModel(DEVICE).state_dict()\n",
    "    pretrained_model = CnnClassifier(n_hidden, pt_layers=pt).to(DEVICE)\n",
    "    optimizer = opt_class(pretrained_model.parameters(), lr=lr)\n",
    "    writer = SummaryWriter('./logs/cnn/%s' % opt_class.__name__)\n",
    "    \n",
    "    return train(pretrained_model, dataloaders_validation, optimizer, writer, n_epochs, ckpt_path, DEVICE, \"test-pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = []\n",
    "for i in range(5):\n",
    "    print(\"Starting training num: %d\" % i)\n",
    "    runs.append(trainCnnFromScratch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training num: 0\n"
     ]
    }
   ],
   "source": [
    "pt_runs = []\n",
    "for i in range(5):\n",
    "    print(\"Starting training num: %d\" % i)\n",
    "    pt_runs.append(trainCnnFromPT())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
